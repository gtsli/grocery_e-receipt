{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import libraries and set print options\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import traceback\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDB_Number</th>\n",
       "      <th>long_name</th>\n",
       "      <th>data_source</th>\n",
       "      <th>gtin_upc</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>date_available</th>\n",
       "      <th>ingredients_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45001524</td>\n",
       "      <td>MOCHI ICE CREAM BONBONS</td>\n",
       "      <td>LI</td>\n",
       "      <td>19022128593</td>\n",
       "      <td>G. T. Japan, Inc.</td>\n",
       "      <td>2017-11-15 19:19:38</td>\n",
       "      <td>2017-11-15 19:19:38</td>\n",
       "      <td>ICE CREAM INGREDIENTS: MILK, CREAM, SUGAR, STR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45001528</td>\n",
       "      <td>CHIPOTLE BARBECUE SAUCE</td>\n",
       "      <td>LI</td>\n",
       "      <td>5051379043735</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>2018-04-26 17:23:31</td>\n",
       "      <td>2018-04-26 17:23:31</td>\n",
       "      <td>WATER, SUGAR, TOMATO PASTE, MOLASSES, DISTILLE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45001529</td>\n",
       "      <td>HOT &amp; SPICY BARBECUE SAUCE</td>\n",
       "      <td>LI</td>\n",
       "      <td>5051379009434</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>2018-04-26 18:17:37</td>\n",
       "      <td>2018-04-26 18:17:37</td>\n",
       "      <td>SUGAR, WATER, DISTILLED VINEGAR, TOMATO PASTE,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45001530</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>LI</td>\n",
       "      <td>5051379019969</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>2018-04-26 17:24:00</td>\n",
       "      <td>2018-04-26 17:24:00</td>\n",
       "      <td>TOMATO PUREE (WATER, TOMATO PASTE), SUGAR, DIS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45001531</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>LI</td>\n",
       "      <td>5051379009526</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>2018-04-26 17:47:41</td>\n",
       "      <td>2018-04-26 17:47:41</td>\n",
       "      <td>SUGAR, DISTILLED VINEGAR, WATER, TOMATO PASTE,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NDB_Number                   long_name data_source       gtin_upc  \\\n",
       "0    45001524     MOCHI ICE CREAM BONBONS          LI    19022128593   \n",
       "1    45001528     CHIPOTLE BARBECUE SAUCE          LI  5051379043735   \n",
       "2    45001529  HOT & SPICY BARBECUE SAUCE          LI  5051379009434   \n",
       "3    45001530              BARBECUE SAUCE          LI  5051379019969   \n",
       "4    45001531              BARBECUE SAUCE          LI  5051379009526   \n",
       "\n",
       "        manufacturer        date_modified       date_available  \\\n",
       "0  G. T. Japan, Inc.  2017-11-15 19:19:38  2017-11-15 19:19:38   \n",
       "1       FRESH & EASY  2018-04-26 17:23:31  2018-04-26 17:23:31   \n",
       "2       FRESH & EASY  2018-04-26 18:17:37  2018-04-26 18:17:37   \n",
       "3       FRESH & EASY  2018-04-26 17:24:00  2018-04-26 17:24:00   \n",
       "4       FRESH & EASY  2018-04-26 17:47:41  2018-04-26 17:47:41   \n",
       "\n",
       "                                 ingredients_english  \n",
       "0  ICE CREAM INGREDIENTS: MILK, CREAM, SUGAR, STR...  \n",
       "1  WATER, SUGAR, TOMATO PASTE, MOLASSES, DISTILLE...  \n",
       "2  SUGAR, WATER, DISTILLED VINEGAR, TOMATO PASTE,...  \n",
       "3  TOMATO PUREE (WATER, TOMATO PASTE), SUGAR, DIS...  \n",
       "4  SUGAR, DISTILLED VINEGAR, WATER, TOMATO PASTE,...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/products.csv') ##read csv as a dataframe\n",
    "data.head() ## show the top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239089"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = data.long_name.tolist() ## get the long_name column into a list\n",
    "len(titles) ## print the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FRESH & EASY',\n",
       " 'FRESH & EASY',\n",
       " 'STATER BROS.',\n",
       " 'STATER BROS.',\n",
       " 'STATER BROS.',\n",
       " 'STATER BROS.',\n",
       " 'GREAT MIDWEST',\n",
       " 'GREAT MIDWEST',\n",
       " 'ICE CREAM',\n",
       " 'FRESH & EASY']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_brands = [x.split(\",\")[0] for x in titles if len(x.split(\",\")) > 1] ## what is the 0th index for items with commas\n",
    "possible_brands[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['KROGER, CHIPMATES, COOKIES, CHOCOLATE CHIPS',\n",
       " \"NEUMAN'S, CARROT PINEAPPLE BREAD, CARROT, PINEAPPLE\",\n",
       " 'SPECIALLY SELECTED, STONE BAKED PIZZA, MOZZARELLA,CHERRY TOMATO AND ARGULA',\n",
       " \"ALBERTSON'S, ICE CREAM, ROCKY ROAD, CHOCOLATE ICE CREAM WITH MARSHMALLOW RIBBON AND MIXED NUTS\",\n",
       " 'NUMI, DECAFFEINATED SAVORY, GREEN TEA BAGS, FENNEL SPICE',\n",
       " 'LANCE, TOAST CHEE, CRACKERS, PEANUT BUTTER',\n",
       " 'WHITE GOLD, SUGAR, PURE CANE, EXTRA FINE GRANULATED',\n",
       " 'HARRIS TEETER, FRESH FOODS MARKET, ARTISAN HUMMUS, CARAMELIZED ONIONS',\n",
       " 'HARRIS TEETER, FRESH FOODS MARKET, KOSHER DILL SPEARS, HOT & SPICY',\n",
       " \"SAM'S CHOICE, WAFFLE COOKIES, CINNAMON, HONEY\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_brands = [x for x in titles if len(x.split(\",\")) == 4]\n",
    "print (len(possible_brands))\n",
    "possible_brands[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RULES:\n",
    "### - The zeroth index seems to be brand for the most part (few exceptions)\n",
    "### - When there are 3 items, the first index is the main product with the 2nd index being a descriptor/flavor/type\n",
    "### - When there are 4 items (only ~4k examples), the 2nd index is the product, the 0th index is still brand, the 3rd index is the descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning - Process Is Commented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = {x.split(\",\")[0] for x in titles if len(x.split(\",\")) > 2 and len(x.split(\",\")[0]) > 1}\n",
    "with open('../data/brands.json', 'w') as outfile:\n",
    "    json.dump(list(brands), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOCHI ICE CREAM BONBONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHIPOTLE BARBECUE SAUCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOT &amp; SPICY BARBECUE SAUCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    long_name\n",
       "0     MOCHI ICE CREAM BONBONS\n",
       "1     CHIPOTLE BARBECUE SAUCE\n",
       "2  HOT & SPICY BARBECUE SAUCE\n",
       "3              BARBECUE SAUCE\n",
       "4              BARBECUE SAUCE"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DROP_COLS = [\n",
    "    'NDB_Number',\n",
    "    'data_source',\n",
    "    'gtin_upc',\n",
    "    'manufacturer',\n",
    "    'date_modified',\n",
    "    'date_available',\n",
    "    'ingredients_english'\n",
    "]\n",
    "data = data.drop(DROP_COLS, axis=1) ## drop unnecessary columns for now\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find the number of commas in each title and only get those with less than 5\n",
    "'''\n",
    "data['num_commas'] = data.apply(lambda x: len(x.long_name.split(\",\"))-1, axis=1)\n",
    "data = data[data['num_commas'] < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This will keep brands and separate it from the rest of the titles with a \",\". EX: \"FRESH & EASY, CANOLA OIL\"\n",
    "'''\n",
    "def remove_descriptor(x):\n",
    "    x_ = x.split(\",\")\n",
    "    if len(x_) == 2 or len(x_) == 3:\n",
    "        if 'fl oz' in x_[1]:\n",
    "            return x_[0].strip()\n",
    "        else:\n",
    "            return x_[0].strip() + \", \" + x_[1].strip()\n",
    "    elif len(x_) == 4:\n",
    "        return x_[0].strip() + \", \" + x_[2].strip()\n",
    "    else:\n",
    "        return x_[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This will keep brands and separate it from the rest of the titles with a \",\". EX: \"FRESH & EASY, CANOLA OIL\"\n",
    "'''\n",
    "def remove_brand_descriptor(x):\n",
    "    x_ = x.split(\",\")\n",
    "    \n",
    "    if len(x_) > 1:\n",
    "        if 'fl oz' in x_[1]:\n",
    "            return x_[0].strip()\n",
    "        else:\n",
    "            return x_[1].strip()\n",
    "    elif len(x_) == 4:\n",
    "        return x_[2].strip()\n",
    "    else:\n",
    "        return x_[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Apply the 2 methods to obtain two different columns with the cleaning process applied\n",
    "'''\n",
    "data['no_brand_descriptor_title'] = data.apply(lambda x: remove_brand_descriptor(x.long_name), axis=1)\n",
    "data['no_descriptor_title'] = data.apply(lambda x: remove_descriptor(x.long_name), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_name</th>\n",
       "      <th>num_commas</th>\n",
       "      <th>no_brand_descriptor_title</th>\n",
       "      <th>no_descriptor_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOCHI ICE CREAM BONBONS</td>\n",
       "      <td>0</td>\n",
       "      <td>MOCHI ICE CREAM BONBONS</td>\n",
       "      <td>MOCHI ICE CREAM BONBONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHIPOTLE BARBECUE SAUCE</td>\n",
       "      <td>0</td>\n",
       "      <td>CHIPOTLE BARBECUE SAUCE</td>\n",
       "      <td>CHIPOTLE BARBECUE SAUCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOT &amp; SPICY BARBECUE SAUCE</td>\n",
       "      <td>0</td>\n",
       "      <td>HOT &amp; SPICY BARBECUE SAUCE</td>\n",
       "      <td>HOT &amp; SPICY BARBECUE SAUCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>0</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>0</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    long_name  num_commas   no_brand_descriptor_title  \\\n",
       "0     MOCHI ICE CREAM BONBONS           0     MOCHI ICE CREAM BONBONS   \n",
       "1     CHIPOTLE BARBECUE SAUCE           0     CHIPOTLE BARBECUE SAUCE   \n",
       "2  HOT & SPICY BARBECUE SAUCE           0  HOT & SPICY BARBECUE SAUCE   \n",
       "3              BARBECUE SAUCE           0              BARBECUE SAUCE   \n",
       "4              BARBECUE SAUCE           0              BARBECUE SAUCE   \n",
       "\n",
       "          no_descriptor_title  \n",
       "0     MOCHI ICE CREAM BONBONS  \n",
       "1     CHIPOTLE BARBECUE SAUCE  \n",
       "2  HOT & SPICY BARBECUE SAUCE  \n",
       "3              BARBECUE SAUCE  \n",
       "4              BARBECUE SAUCE  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238333\n"
     ]
    }
   ],
   "source": [
    "#remove leading symbols\n",
    "edited_list = data.no_descriptor_title.tolist()\n",
    "output = [re.sub('[![\\]@#$*+\\\\\\\\/\\'\"}{)(]', '', x) for x in edited_list]\n",
    "output2 = [\"0\"+x if x[0] == \".\" else x for x in output]\n",
    "output3 = [x[1:] if x[0] == \" \" else x for x in output2]\n",
    "\n",
    "\n",
    "print (len(output2))\n",
    "data['no_descriptor_title'] = output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Turn the dataframe's no brand and no descriptor titles into a list and clean out bad case\n",
    "'''\n",
    "no_brand_descrip = [x for x in list(set(data.no_brand_descriptor_title)) if x != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Turn the dataframe's no descriptor titles into a list and clean out bad case\n",
    "'''\n",
    "no_descrip = [x for x in list(set(data.no_descriptor_title)) if x != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OPTIMUM SLIM CEREAL',\n",
       " 'GUMMY BUNNY',\n",
       " 'GERMAN STYLE PICKLES',\n",
       " 'GIANT EASTER BUNNY',\n",
       " 'NABULSI SEMI-SOFT CHEESE',\n",
       " \"Kellogg's Special K Cereal Bars Dark Chocolate Salted Nut 5.5oz\",\n",
       " 'PINE NUTS (PIGNOLAS)',\n",
       " 'HOT LINK',\n",
       " 'FRUIT CUPS',\n",
       " 'MERRY MINT MIX']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_brand_descrip[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDITIONAL_DESCRIPTORS = [\n",
    "    'ORGANIC',\n",
    "    'NATURAL',\n",
    "    'NATURALLY',\n",
    "    'PREMIUM',\n",
    "    'PURE',\n",
    "    '100%',\n",
    "    'FRESH SELECTIONS',\n",
    "    'HOMESTYLE',\n",
    "    '®',\n",
    "    'IMPORTED',\n",
    "    'QUALITY',\n",
    "    'ALL',\n",
    "    'HOME MADE',\n",
    "    'HOME STYLE',\n",
    "    'RICH',\n",
    "    'ORIGINAL',\n",
    "    'ENRICHED',\n",
    "    'KOSHER',\n",
    "]\n",
    "\n",
    "with open('../data/descriptors.json', 'w') as outfile:\n",
    "    json.dump(ADDITIONAL_DESCRIPTORS, outfile)\n",
    "\n",
    "##remove everything with oz? and ct? and lb? and ounce? take out all gatordade entries?\n",
    "UNITS = [\n",
    "    'oz',\n",
    "    'ounce',\n",
    "    'ct',\n",
    "    'lb',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_descrip_cleaning(data):\n",
    "    \n",
    "    ADDITIONAL_DESCRIPTORS = [\n",
    "        'ORGANIC',\n",
    "        'NATURAL',\n",
    "        'NATURALLY',\n",
    "        'PREMIUM',\n",
    "        'PURE',\n",
    "        '100%',\n",
    "        'FRESH SELECTIONS',\n",
    "        'HOMESTYLE',\n",
    "        '®',\n",
    "        'IMPORTED',\n",
    "        'QUALITY',\n",
    "        'ALL',\n",
    "        'HOME MADE',\n",
    "        'HOME STYLE',\n",
    "        'RICH',\n",
    "        'ORIGINAL',\n",
    "        'ENRICHED',\n",
    "        'KOSHER',\n",
    "    ]\n",
    "    for new_descrip in ADDITIONAL_DESCRIPTORS:\n",
    "        for idx, prod in enumerate(data):\n",
    "            prod_split = prod.upper().split(\" \")\n",
    "            if new_descrip in prod_split:\n",
    "                prod_split.remove(new_descrip)\n",
    "                data[idx] = \" \".join(prod_split)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_units(data):\n",
    "    ##remove everything with oz? and ct? and lb? and ounce? take out all gatordade entries?\n",
    "    UNITS = [\n",
    "        'OZ',\n",
    "        'OUNCE',\n",
    "        'CT',\n",
    "        'LB',\n",
    "    ]\n",
    "    for unit in UNITS:\n",
    "        for idx, prod in enumerate(data):\n",
    "            split_prod = prod.upper().split(\" \")\n",
    "            if unit in split_prod:\n",
    "                try:\n",
    "                    for i, word in enumerate(split_prod):\n",
    "                        if unit in split_prod[i]:\n",
    "                            del split_prod[i]\n",
    "                            del split_prod[i-1]\n",
    "                            data[idx] = \" \".join(split_prod)\n",
    "                except Exception:\n",
    "                    print (traceback.print_exc())\n",
    "                    print (\"failed on: \", split_prod)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_gatorade(data):\n",
    "    return [x for x in data if \"GATORADE\" not in x.upper()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned out 6204 product titles\n",
      "Cleaned out 541 product titles\n",
      "Cleaned out 189 product titles\n"
     ]
    }
   ],
   "source": [
    "cleaned_no_brand_descrip = set(extra_descrip_cleaning(no_brand_descrip))\n",
    "print (\"Cleaned out %i product titles\" %(len(no_brand_descrip) - len(cleaned_no_brand_descrip)))\n",
    "\n",
    "cleaned_no_brand_descrip_2 = set(clean_units(list(cleaned_no_brand_descrip)))\n",
    "print (\"Cleaned out %i product titles\" %(len(cleaned_no_brand_descrip) - len(cleaned_no_brand_descrip_2)))\n",
    "\n",
    "cleaned_no_brand_descrip_3 = list(set(remove_gatorade(list(cleaned_no_brand_descrip_2))))\n",
    "print (\"Cleaned out %i product titles\" %(len(cleaned_no_brand_descrip_2) - len(cleaned_no_brand_descrip_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105730\n"
     ]
    }
   ],
   "source": [
    "cleaned_no_brand_descrip_3 = [x for x in cleaned_no_brand_descrip_3 if x != \"\"]\n",
    "print (len(cleaned_no_brand_descrip_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save the lists as a json file\n",
    "'''\n",
    "\n",
    "with open('../data/cleaned_branded_data.json', 'w') as outfile:\n",
    "    json.dump([x.replace(',', '') for x in no_descrip], outfile)\n",
    "    \n",
    "with open('../data/cleaned_data.json', 'w') as outfile:\n",
    "    json.dump(cleaned_no_brand_descrip_3, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
